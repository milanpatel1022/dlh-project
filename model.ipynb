{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292f2ed4-397d-42b3-a60f-febc19b81e8e",
   "metadata": {},
   "source": [
    "- Link to GitHub repo: https://github.com/milanpatel1022/dlh-project\n",
    "- Link to YouTube video: https://www.youtube.com/watch?v=tHiYQ-XVV18&ab_channel=MilanJanakPatel\n",
    "\n",
    "# Introduction\n",
    "***\n",
    "## Background\n",
    "    - Paper: CNN-DDI\n",
    "    - I built off of the DDIMDL repo code (which was specified in the paper selection list) to follow this paper\n",
    "\n",
    "### Type of problem\n",
    "    - Predicting events associated to Drug-Drug Interactions (DDIs)\n",
    "    - DDIs are the reactions between two or more drugs\n",
    "### Importance\n",
    "    - Unexpected DDIs can cause serious and unforeseen health issues\n",
    "    - Multiple drug consumption is becoming increasingly common\n",
    "    - The study of DDIs is important to drug discovery and development, but also for increasing the safety potential of patients who may be consuming multiple drugs\n",
    "### Difficulty\n",
    "    - In the past, DDIs were solely discovered through wet experiments\n",
    "    - This method is labor-intensive and time-consuming\n",
    "### Methods and effectiveness\n",
    "    - In recent years, databases containing large amounts of drug data have been constructed using information from literature and reports\n",
    "    - This has allowed for ML methods to be applied to this task of predicting DDI associated events, thereby reducing efforts, time, and cost\n",
    "### Paper Proposal\n",
    "    - This paper proposes a novel CNN architecture in the supervised learning approach to predicting DDIs\n",
    "### Paper Innovations\n",
    "    - This paper's innovations include the novel CNN architecture + utilizing a new drug feature that older papers haven't (called drug category) in training/prediction\n",
    "### Paper Metrics\n",
    "    - Outperforms all ML methods that came before it, including DDIMDL (DDIMDL was trained on different features)\n",
    "    - ACC      AUPR     AUC       F1       Precision    Recall\n",
    "      0.8871   0.9251   0.9980    0.7496   0.8556       0.7220\n",
    "### Paper Contribution to Research\n",
    "    - This paper's contribution is identfying that the CNN architecture along with the drug category feature, can allow for improved DDI predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f65fb8-114d-40ac-b44b-163ba085c1ec",
   "metadata": {},
   "source": [
    "# Scope of Reproducibility\n",
    "***\n",
    "## Hypothesis 1\n",
    "    - Drugs with similar features will interact similarly\n",
    "    - Ex: If Drug A and B interact with each other and have a biological impact\n",
    "        - If Drug C is similar to A, it will likely interact with B in the same manner A does\n",
    "    - CNNs will capture patterns in the feature similarity scores of drugs and accurately predict interactions accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55868c92-415e-4d75-8f09-8c0c418816d3",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "***\n",
    "## IMPORTANT NOTE\n",
    "    - All data extraction, data processing, model, evaluation code is present in this notebook. main() will begin running the entire process.\n",
    "        - Each cell/section of code will be highlighted to what its high-level purpose is\n",
    "        - I understand the code is out of order of what the template specifies, but nonetheless, the implementations are all there\n",
    "        - I have added highly detailed comments throughout each and every part of the code for your understanding as well.\n",
    "    - Most of this code comes from the DDIMDL paper\n",
    "    - I have made several changes to remove bugs, unnecessary code, add detailed explanations, and to include the CNN architecture specified in CNN-DDI\n",
    "\n",
    "## Data\n",
    "### Source\n",
    "    - DDIMDL repo (within the event.db file) -> ultimately sourced from DrugBank\n",
    "    - Drug table: contains 572 drugs and their features (id, target, enzyme, pathway, smile, name)\n",
    "    - Event table: 37264 DDIs between 572 drugs (id1, name1, id2, name2, interaction)\n",
    "    - Extraction table: each interaction transformed to tuple {mechanism, action, drugA, drugB} -> done using NLPProcess code from DDIMDL\n",
    "    - Event_number table: interaction/event mapped to its frequency\n",
    "### Data Process\n",
    "    - 4 (572x572) similarity matrices created and data split into training/test sets using 5-fold cross validation\n",
    "    - Why 4 matrices? 4 features to consider\n",
    "    - Why 572 x 572? Because 572 drugs\n",
    "    - In each feature matrix, each drug is represented by a binary vector\n",
    "## Model Architecture\n",
    "### Layers\n",
    "    - 5 convolutional layers followed by 2 fully connected layers\n",
    "    - 2 max pooling layers in between\n",
    "### Activation functions\n",
    "    - ReLU activation used after each convolutional layer\n",
    "    - Softmax used in output layer\n",
    "## Training Objectives\n",
    "### Loss Function\n",
    "    - Categorical Cross Entropy (aka Softmax Loss)\n",
    "### Optimizer\n",
    "    - Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9d05a-d97d-4aa6-95b4-fbcbd112a1ff",
   "metadata": {},
   "source": [
    "# Results\n",
    "***\n",
    "## Note\n",
    "    - Results should be taken with a grain of salt. I was not able to get the drug category feature into my dataset\n",
    "    - The results are from training using 4 features (pathway, target, enzyme, and smile)\n",
    "    - The paper uses drug category instead of smile as a feature.\n",
    "    - My results are very similar to the results from the paper even though I used one different feature.\n",
    "## Stored in 2 Files\n",
    "    - First CSV: shows 11 performance metrics describing the the overall classification performance (11 rows, 1 column)\n",
    "    - Second CSV: shows 6 performance metrics describing the per-event classification performance (65 rows, 6 columns)\n",
    "## Figures\n",
    "| Model                | ACC    | AUPR   | AUC    | F1     | Precision | Recall |\r\n",
    "|----------------------|--------|--------|--------|--------|-----------|--------|\r\n",
    "| CNN-DDI (Paper)      | 0.8871 | 0.9251 | 0.9980 | 0.7496 | 0.8556    | 0.7220 |\r\n",
    "| My Implementation    | 0.8710 | 0.9329 | 0.9979 | 0.7523 | 0.8262    | 0.7111 |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b7e7a-d578-4c0a-9aa2-d87797223784",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "***\n",
    "Training epochs changed from 10 to 3 to demo that the model is properly training/learning\n",
    "## Reproducibility\n",
    "    - This paper was mostly reproducible.\n",
    "    - This paper has no code, so instead, the code from DDIMDL was used as the foundation\n",
    "    - The DDIMDL repo has already acquired the data and placed it into a database file\n",
    "    - CNN-DDI says it uses data acquired from DDIMDL\n",
    "    - However, CNN-DDI uses a new drug feature that is not present in the Drug table in the database\n",
    "    - Neither paper explained the data acquisition method, only where the data came from\n",
    "    - I have been unable to acquire that drug category feature.\n",
    "    \n",
    "## What was easy/difficult?\n",
    "    - It was difficult fully understanding the DDIMDL code so I can debug it and modify it to work with CNN architecture instead of the DNN it was using\n",
    "## Suggestions to authors\n",
    "    - Explain how the data was acquired\n",
    "    - Provide some code\n",
    "## What I would do in the next phase\n",
    "    - Figure out how to get that drug category feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8ae5d-28c3-4ba0-baa8-4daca0506e66",
   "metadata": {},
   "source": [
    "# References\n",
    "***\n",
    "### [1] Zhang, C., Lu, Y. & Zang, T. CNN-DDI: a learning-based method for predicting drug–drug interactions using convolution neural networks. BMC Bioinformatics 23 (Suppl 1), 88 (2022). https://doi.org/10.1186/s12859-022-04612-2\n",
    "### [2] Yifan Deng, Xinran Xu, Yang Qiu, Jingbo Xia, Wen Zhang, Shichao Liu, A multimodal deep learning framework for predicting drug–drug interaction events, Bioinformatics, Volume 36, Issue 15, August 2020, Pages 4316–4322, https://doi.org/10.1093/bioinformatics/btaa501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9461dfd4-ad14-43bd-b1cc-85c898fb0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import sqlite3\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Activation, Conv1D, MaxPooling1D, Flatten, Add\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f181f4-0f6f-4dc8-85fd-425ee71bd89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_num = 65\n",
    "droprate = 0.3\n",
    "vector_size = 572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b739b37-baca-4534-b3c1-ae211c7953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MODEL ARCHITECTURE AND CODE'''\n",
    "\n",
    "def CNN():\n",
    "    #TO-DO: still need to add residual connection\n",
    "    \n",
    "    # Define input layer (note: batch_size doesn't need to be included in shape but it is implied... so input shape is: [batch_size, 1144, 1]\n",
    "    train_input = Input(shape=(vector_size * 2, 1), name='Inputlayer')\n",
    "\n",
    "    # Define model architecture (followed CNN-DDI paper which mentioned the 5 conv layers and 2 dense/fc layers\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(train_input) #64 output filters\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x) #128 output filters\n",
    "    x = MaxPooling1D(pool_size=2)(x) #reduce dimensionality & extract important features\n",
    "\n",
    "    #residual block\n",
    "    residual = Conv1D(128, kernel_size=1, activation='linear')(x)\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x) #128 output filters\n",
    "    x = Conv1D(128, kernel_size=3, activation='relu', padding='same')(x) #128 output filters\n",
    "    x = Add()([x, residual]) #skip connection\n",
    "    \n",
    "    x = MaxPooling1D(pool_size=2)(x) #reduce dimensionality & extract important features\n",
    "    \n",
    "    x = Conv1D(256, kernel_size=3, activation='relu')(x) #256 output filters\n",
    "    \n",
    "    x = Flatten()(x) #flatten feature vector to prepare for dense/fc layers\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    output = Dense(65, activation='softmax')(x) #apply softmax to get probability distribution over the 65 output classes\n",
    "\n",
    "    # Define the model (specify the input and output layers)\n",
    "    model = Model(inputs=train_input, outputs=output)\n",
    "\n",
    "    # Compile the model (optimizer, loss function, and evaluation metric)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc60d3b-811d-43cd-900f-444b093e3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA PROCESSING PART 1'''\n",
    "\n",
    "'''This function is called separately for each of the 4 features'''\n",
    "\n",
    "def prepare(df_drug, feature_list, vector_size, mechanism, action, drugA, drugB):\n",
    "    \n",
    "    #dicts to store labels and features\n",
    "    d_label = {}\n",
    "    d_feature = {}\n",
    "\n",
    "    #store events as strings (mechanism + action = event)\n",
    "    d_event=[] #length: 37264 (that many events have occurred)\n",
    "    for i in range(len(mechanism)):\n",
    "        d_event.append(mechanism[i]+\" \"+action[i])\n",
    "\n",
    "    \n",
    "    #all 37264 events end up being classified into 65 unique events (and our models will predict two drugs to have one of these 65 types of events)\n",
    "    count={} #65 events mapped to their individual occurrence count\n",
    "    for i in d_event:\n",
    "        if i in count:\n",
    "            count[i]+=1\n",
    "        else:\n",
    "            count[i]=1\n",
    "\n",
    "    #sort events by count in descending order\n",
    "    list1 = sorted(count.items(), key=lambda x: x[1],reverse=True)\n",
    "\n",
    "    #each event is assigned a label (index in this case) where label 0 is the most frequently occuring event and label 64 is the least\n",
    "    for i in range(len(list1)):\n",
    "        d_label[list1[i][0]]=i\n",
    "\n",
    "    #initialize empty vector for each of the 572 drugs\n",
    "    vector = np.zeros((len(np.array(df_drug['name']).tolist()), 0), dtype=float) #shape: (572, 0)... we set up all the rows in our feature matrix\n",
    "    \n",
    "    for i in feature_list:\n",
    "        #horizontally stack the feature vectors into our vector object\n",
    "        vector = np.hstack((vector, feature_vector(i, df_drug, vector_size)))\n",
    "\n",
    "    #vector is now shape: (572, 572) -> it is our similarity matrix\n",
    "        \n",
    "    #Map each drug name to its corresponding feature vector from the vector calculated above\n",
    "    for i in range(len(np.array(df_drug['name']).tolist())):\n",
    "        d_feature[np.array(df_drug['name']).tolist()[i]] = vector[i]\n",
    "    \n",
    "    new_feature = [] #store new feature vectors\n",
    "    new_label = [] #store new labels\n",
    "\n",
    "\n",
    "    #iterate over length of events (length is 37264)\n",
    "    for i in range(len(d_event)):\n",
    "        #horizontally concatenate feature vectors of drugA + drugB (note: we are doing this for each event)\n",
    "        new_feature.append(np.hstack((d_feature[drugA[i]], d_feature[drugB[i]])))\n",
    "\n",
    "        #event i is our key into d_label, which tells us which one of the 65 labels it is assigned\n",
    "        new_label.append(d_label[d_event[i]])\n",
    "\n",
    "    #shape: (37264, 1144)... 37264 = number of events between 572 drugs; 1144 = (572x2) since we are hstacking feature vectors of two drugs\n",
    "    new_feature = np.array(new_feature) \n",
    "\n",
    "    #shape: (37264, )... label for each event\n",
    "    new_label = np.array(new_label)\n",
    "\n",
    "    return (new_feature, new_label, event_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fc39df-8628-43af-bdab-f92a5c0f6e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA PROCESSING PART 2'''\n",
    "\n",
    "'''\n",
    "This function is called separately for each of the 4 features\n",
    "It will generate the respective feature vectors for each drug\n",
    "'''\n",
    "\n",
    "def feature_vector(feature_name, df, vector_size):\n",
    "    # df are the 572 kinds of drugs\n",
    "    \n",
    "    # Jaccard Similarity: takes in matrix that represents the feature vectors of drugs\n",
    "    #we want to calculate the similarity between the feature vectors of the drugs\n",
    "    def Jaccard(matrix):\n",
    "        matrix = np.mat(matrix) #convert input matrix to numpy matrix\n",
    "        \n",
    "        numerator = matrix * matrix.T #calculate numerator of Jaccard similarity (dot product of matrix with the transpose of itself)\n",
    "        denominator = np.ones(np.shape(matrix)) * matrix.T + matrix * np.ones(np.shape(matrix.T)) - matrix * matrix.T #calculate denominator\n",
    "\n",
    "        #return the Jaccard similarity matrix\n",
    "        return numerator / denominator\n",
    "\n",
    "    '''\n",
    "    Each of the 4 features is defined by a set of descriptors\n",
    "        - Ex) Smile feature has 881 descriptors (so the drug is represented by a length 881 binary vector in terms of the smile feature)\n",
    "        - Ex) Target feature has 1162 descriptors (so the drug is represented by a length 1162 binary vector in terms of the target feature)\n",
    "    '''\n",
    "\n",
    "    all_descriptors = [] #stores all the unique descriptors of this feature\n",
    "\n",
    "    #drug_list=[\"P30556|P05412\",\"P28223|P46098|……\"]\n",
    "    drug_list = np.array(df[feature_name]).tolist() #list of length 572 (for each drug, we list its descriptors)\n",
    "\n",
    "    #For each of the 572 drugs \n",
    "    for i in drug_list:\n",
    "        #Identify its descriptors\n",
    "        for each_descriptor in i.split('|'):\n",
    "            #Add any unseen descriptors to all_descriptors (in this fashion, we obtain all the descriptors for a feature)\n",
    "            if each_descriptor not in all_descriptors:\n",
    "                all_descriptors.append(each_descriptor)\n",
    "\n",
    "    #shape: (572, len(all_descriptors))\n",
    "    feature_matrix = np.zeros((len(drug_list), len(all_descriptors)), dtype=float)\n",
    "\n",
    "    #dataframe where rows are 572 drugs and columns are all_descriptors (columns can be indexed by descriptor name)\n",
    "    df_feature = DataFrame(feature_matrix, columns=all_descriptors)\n",
    "\n",
    "    #For each drug's feature vector -> mark cell as 1 if it has that corresponding descriptor present (else it will remain 0)\n",
    "    for i in range(len(drug_list)):\n",
    "        for each_descriptor in df[feature_name].iloc[i].split('|'):\n",
    "            df_feature[each_descriptor].iloc[i] = 1\n",
    "\n",
    "    #Calculate Jaccard Similarity matrix (shape: (572, 572) where each element [i, j] represents similarity between drug i and drug j)\n",
    "    sim_matrix = Jaccard(np.array(df_feature))\n",
    "\n",
    "    #Apply PCA to reduce noise/redundancy in data while keeping dimensionality the same\n",
    "    pca = PCA(n_components=vector_size)\n",
    "    pca.fit(np.asarray(sim_matrix))\n",
    "    sim_matrix = pca.transform(np.asarray(sim_matrix))\n",
    "\n",
    "    #shape: (572, 572)\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f30bdf-ffa8-49c7-bd64-9c3ea75da87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATA PROCESSING PART 3'''\n",
    "\n",
    "'''\n",
    "This function assigns fold numbers to each of the 37264 events for cross-validation\n",
    "It is basically a helper to the cross_validation function of ours\n",
    "'''\n",
    "\n",
    "def get_index(label_matrix, event_num, seed, CV):\n",
    "\n",
    "    #store the fold number for each sample in the dataset (fold numbers range from 0 to 4)\n",
    "    index_all_class = np.zeros(len(label_matrix)) #shape: (37264, )\n",
    "\n",
    "    #for each event number (0 through 64)\n",
    "    for j in range(event_num):\n",
    "        \n",
    "        #find label indices where the event number matches event j\n",
    "        index = np.where(label_matrix == j)\n",
    "\n",
    "        #initialize KFold cross-validator with CV (5) folds, shuffling data, and setting random seed\n",
    "        kf = KFold(n_splits=CV, shuffle=True, random_state=seed)\n",
    "        k_num = 0 #keep track of fold number\n",
    "\n",
    "        #for the samples that were matched to j -> split them into training and test sets across 5 folds\n",
    "        for train_index, test_index in kf.split(range(len(index[0]))):\n",
    "\n",
    "            #for the current training & test split/fold, assign the test indices to current fold number\n",
    "            index_all_class[index[0][test_index]] = k_num\n",
    "            k_num += 1 #increment fold number for next iteration\n",
    "\n",
    "    #for each of the 37264 events, we now know in which fold it is treated as test data. else, it will be used as training data in the other folds.\n",
    "    return index_all_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97cdae6a-1795-4363-afb8-46c8c3b8e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TRAINING CODE'''\n",
    "\n",
    "'''\n",
    "This function performs 5-fold cross validation for each of the 4 feature similarity matrices (so 20 different CNN models are trained)\n",
    "The results are aggregated and overall and per-event performance is evaluated\n",
    "'''\n",
    "\n",
    "def cross_validation(feature_matrix, label_matrix, event_num, seed, CV):\n",
    "    #evaluation results across all events (CSV file will have 11 rows and 1 column)\n",
    "    all_eval_type = 11\n",
    "    result_all = np.zeros((all_eval_type, 1), dtype=float)\n",
    "\n",
    "    #evaluation results for each event (CSV file will have 65 rows and 6 columns)\n",
    "    each_eval_type = 6\n",
    "    result_eve = np.zeros((event_num, each_eval_type), dtype=float)\n",
    "    \n",
    "    y_true = np.array([]) #store true labels\n",
    "    y_pred = np.array([]) #store predicted labels\n",
    "    y_score = np.zeros((0, event_num), dtype=float) #store scores of predictions\n",
    "\n",
    "    #get fold numbers for each of the 37264 events for cross-validation\n",
    "    index_all_class = get_index(label_matrix, event_num, seed, CV) #shape: (37264, )\n",
    "\n",
    "    #NOTE: we will train 20 models (for each fold (5) -> for each feature matrix (4) = 5 * 4 = 20)\n",
    "\n",
    "    #for each fold (0 through 4)\n",
    "    for k in range(CV):\n",
    "        print(f'Training for Fold {k}')\n",
    "        \n",
    "        train_index = np.where(index_all_class != k) #training indices are all indices not marked as k\n",
    "        test_index = np.where(index_all_class == k) #test indices are all indices marked as k\n",
    "        pred = np.zeros((len(test_index[0]), event_num), dtype=float) #initialize array to store predicted scores for testing set\n",
    "\n",
    "        #iterate over each of our 4 feature similarity matrices (smile, target, enzyme, pathway)\n",
    "        for i in range(len(feature_matrix)):\n",
    "            print(f'Training for Feauture {i}')\n",
    "            \n",
    "            #separate the data into training and testing sets based on the current fold indices we calculated above\n",
    "            x_train = feature_matrix[i][train_index] #shape: (train_index, 1144)\n",
    "            x_test = feature_matrix[i][test_index] #shape: (test_index, 1144)\n",
    "            y_train = label_matrix[train_index] #shape: (train_index, )\n",
    "            y_test = label_matrix[test_index] #shape: (test_index, )\n",
    "\n",
    "            #one-hot encoding (each label represented by length 65 vector, with 1 at index corresponding to label number and 0's elsewhere)\n",
    "            #shape: (y_train, 65)\n",
    "            y_train_one_hot = np.array(y_train)\n",
    "            y_train_one_hot = (np.arange(y_train_one_hot.max() + 1) == y_train[:, None]).astype(dtype='float32')\n",
    "            \n",
    "            # one-hot encoding\n",
    "            y_test_one_hot = np.array(y_test)\n",
    "            y_test_one_hot = (np.arange(y_test_one_hot.max() + 1) == y_test[:, None]).astype(dtype='float32')\n",
    "\n",
    "            #let's train a sub-model in regards to the current feature\n",
    "            cnn = CNN()\n",
    "\n",
    "            #technique to prevent overfitting (monitors model performance on the validation set & stops when performance stops improving/worsens)\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "\n",
    "            #our data is compatible with the original DNN from paper, but with our CNN, an extra dimension is required. let's add it\n",
    "            #now data is of shape: [batch_size, 1144, 1]\n",
    "            x_train = np.expand_dims(x_train, axis=-1)\n",
    "            x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "            #fit the model to the training data\n",
    "            #epochs originally 10, let's just do 3 for time and demo purposes\n",
    "            cnn.fit(x_train, y_train_one_hot, batch_size=128, epochs=10, validation_data=(x_test, y_test_one_hot),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "            # Save the trained model\n",
    "            if cnn is not None:\n",
    "                print(\"model should be saved???\")\n",
    "                print(cnn)\n",
    "\n",
    "            #save model and its weights separately (because pickle and joblib are not working)\n",
    "            model_json = cnn.to_json()\n",
    "            model_filename = os.path.join(\"./models\", f\"fold_{k}_feature_{i}_model.json\")\n",
    "            \n",
    "            with open(model_filename, 'w') as file:\n",
    "                file.write(model_json)\n",
    "\n",
    "            weights_filename = os.path.join(\"./model_weights\", f\"fold_{k}_feature_{i}.weights.h5\")\n",
    "            cnn.save_weights(weights_filename)\n",
    "\n",
    "            \n",
    "            #make predictions for the testing data and append it to current fold's pred array\n",
    "            pred += cnn.predict(x_test)\n",
    "                \n",
    "\n",
    "        #AGGREGATE RESULTS\n",
    "        pred_score = pred / len(feature_matrix) #calculate the average prediction score for each sample across all folds\n",
    "        pred_type = np.argmax(pred_score, axis=1) #determine the predicted event number by taking index of max value in each row of pred_score\n",
    "        \n",
    "        y_true = np.hstack((y_true, y_test)) #horizontally stack true labels to keep track of true labels across all folds\n",
    "        y_pred = np.hstack((y_pred, pred_type)) #horizontally stack predicted labels to keep track of predicted labels across all folds\n",
    "\n",
    "        #vertically stack prediction scores to create matrix where each row represents the prediction scores for each sample across all folds\n",
    "        #columns represent each event number\n",
    "        y_score = np.row_stack((y_score, pred_score))\n",
    "\n",
    "    '''\n",
    "    Recap\n",
    "        - Predictions from 20 trained models are combined to obtain an overall more robust prediction (rather than selecting a single best performing model)\n",
    "    '''\n",
    "    \n",
    "    #calculate evaluation metrics based on predicted labels and scores (returns overall and event-specific evaluation metrics)\n",
    "    result_all, result_eve = evaluate(y_pred, y_score, y_true, event_num)\n",
    " \n",
    "    return result_all, result_eve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f396cb05-288e-45ea-9ccd-580dc1544e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EVALUATION CODE'''\n",
    "\n",
    "'''\n",
    "This function computes multiple evaluation metrics (accuracy, ROC AUPR, ROC AUC, precision, recall, f1)\n",
    "    - For both overall performance and per individual event\n",
    "'''\n",
    "\n",
    "def evaluate(pred_type, pred_score, y_test, event_num):\n",
    "\n",
    "    #evaluation results across all events (CSV file will have 11 rows and 1 column)\n",
    "    all_eval_type = 11 #11 evaluation metrics\n",
    "    result_all = np.zeros((all_eval_type, 1), dtype=float)\n",
    "\n",
    "    #evaluation results for each event (CSV file will have 65 rows and 6 columns)\n",
    "    each_eval_type = 6 #6 evaluation metrics\n",
    "    result_eve = np.zeros((event_num, each_eval_type), dtype=float)\n",
    "\n",
    "    #convert true labels (y_test) and predicted labels (pred_type) to one-hot encoded arrays (just like we did in cross_validation)\n",
    "    y_one_hot = label_binarize(y_test, classes=np.arange(event_num))\n",
    "    pred_one_hot = label_binarize(pred_type, classes=np.arange(event_num))\n",
    "\n",
    "    #results across all events\n",
    "    result_all[0] = accuracy_score(y_test, pred_type) #compute overall accuracy\n",
    "    \n",
    "    result_all[1] = roc_aupr_score(y_one_hot, pred_score, average='micro') #compute micro-average AUPR score\n",
    "    result_all[2] = roc_aupr_score(y_one_hot, pred_score, average='macro') #compute macro-average AUPR score\n",
    "    \n",
    "    result_all[3] = roc_auc_score(y_one_hot, pred_score, average='micro') #compute micro-average ROC_AUC score\n",
    "    result_all[4] = roc_auc_score(y_one_hot, pred_score, average='macro') #compute macro-average ROC_AUC score\n",
    "    \n",
    "    result_all[5] = f1_score(y_test, pred_type, average='micro') \n",
    "    result_all[6] = f1_score(y_test, pred_type, average='macro')\n",
    "    \n",
    "    result_all[7] = precision_score(y_test, pred_type, average='micro')\n",
    "    result_all[8] = precision_score(y_test, pred_type, average='macro')\n",
    "    \n",
    "    result_all[9] = recall_score(y_test, pred_type, average='micro')\n",
    "    result_all[10] = recall_score(y_test, pred_type, average='macro')\n",
    "\n",
    "    #results for each event\n",
    "    for i in range(event_num):\n",
    "        #calculate accuracy for each event class (will be stored in 1st column)\n",
    "        result_eve[i, 0] = accuracy_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel())\n",
    "\n",
    "        #calculate ROC AUPR score for each event class (will be stored in 2nd column)\n",
    "        result_eve[i, 1] = roc_aupr_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
    "                                          average=None)\n",
    "        #ROC AUC score\n",
    "        result_eve[i, 2] = roc_auc_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
    "                                         average=None)\n",
    "\n",
    "        #f1 score\n",
    "        result_eve[i, 3] = f1_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
    "                                    average='binary')\n",
    "\n",
    "        #precision score\n",
    "        result_eve[i, 4] = precision_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
    "                                           average='binary')\n",
    "\n",
    "        #recall score\n",
    "        result_eve[i, 5] = recall_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
    "                                        average='binary')\n",
    "        \n",
    "    return [result_all, result_eve]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf3aa8f-f615-4ecf-a6ee-f0fda5ab8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EVALUATION CODE HELPER FUNCTION'''\n",
    "\n",
    "def roc_aupr_score(y_true, y_score, average=\"macro\"):\n",
    "    def _binary_roc_aupr_score(y_true, y_score):\n",
    "        precision, recall, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "        return auc(recall, precision) #update\n",
    "\n",
    "    def _average_binary_score(binary_metric, y_true, y_score, average):  # y_true= y_one_hot\n",
    "        if average == \"binary\":\n",
    "            return binary_metric(y_true, y_score)\n",
    "        if average == \"micro\":\n",
    "            y_true = y_true.ravel()\n",
    "            y_score = y_score.ravel()\n",
    "        if y_true.ndim == 1:\n",
    "            y_true = y_true.reshape((-1, 1))\n",
    "        if y_score.ndim == 1:\n",
    "            y_score = y_score.reshape((-1, 1))\n",
    "        n_classes = y_score.shape[1]\n",
    "        score = np.zeros((n_classes,))\n",
    "        for c in range(n_classes):\n",
    "            y_true_c = y_true.take([c], axis=1).ravel()\n",
    "            y_score_c = y_score.take([c], axis=1).ravel()\n",
    "            score[c] = binary_metric(y_true_c, y_score_c)\n",
    "        return np.average(score)\n",
    "\n",
    "    return _average_binary_score(_binary_roc_aupr_score, y_true, y_score, average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a7c293-c13e-4cf2-a503-49731b5be490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SAVING EVALUATION RESULTS TO TWO CSV FILES'''\n",
    "\n",
    "def save_result(feature_name, result_type, clf_type, result):\n",
    "    with open(feature_name + '_' + result_type + '_' + clf_type+ '.csv', \"w\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for i in result:\n",
    "            writer.writerow(i)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1842b6-d5b4-4f1a-9a76-91dcac2dbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DATA EXTRACTION IS DONE HERE\n",
    "DATA PROCESSING AND TRAINING CODE IS CALLED FROM HERE\n",
    "SAVING RESULTS IS CALLED FROM HERE AS WELL\n",
    "'''\n",
    "\n",
    "def main(feature_list=[\"smile\", \"target\", \"enzyme\", \"pathway\"], classifier=\"CNN\"):\n",
    "    seed = 0\n",
    "    CV = 5\n",
    "\n",
    "    #Establish connection to SQLite DB and load in 3 tables\n",
    "    conn = sqlite3.connect(\"event.db\")\n",
    "    \n",
    "    df_drug = pd.read_sql('select * from drug;', conn) #drug info (id, the 4 drug features, name)\n",
    "    df_event = pd.read_sql('select * from event_number;', conn) #frequency of events (event, frequency)\n",
    "    df_interaction = pd.read_sql('select * from event;', conn) #event info (id1, name1, id2, name2, interaction)\n",
    "\n",
    "    extraction = pd.read_sql('select * from extraction;', conn) #mechanism, action, drugA, drugB\n",
    "    mechanism = extraction['mechanism']\n",
    "    action = extraction['action']\n",
    "    drugA = extraction['drugA']\n",
    "    drugB = extraction['drugB']\n",
    "\n",
    "    featureName=\"+\".join(feature_list) #concatenate feature names into single string separated by \"+\"\n",
    "    clf_list = [classifier]\n",
    "\n",
    "    #these two will store the overall and event-wise evaluation results\n",
    "    result_all = {}\n",
    "    result_eve = {}\n",
    "\n",
    "    #store the feature matrix for each feature\n",
    "    all_matrix = []\n",
    "\n",
    "    #read all drug names from txt and store in drugList\n",
    "    drugList=[]\n",
    "    for line in open(\"DrugList.txt\",'r'):\n",
    "        drugList.append(line.split()[0])\n",
    "\n",
    "    #loop through every feature -> prepare the feature matrix -> append to all_matrix\n",
    "    for feature in feature_list:\n",
    "        print(feature)\n",
    "        new_feature, new_label, event_num = prepare(df_drug, [feature], vector_size, mechanism,action,drugA,drugB)\n",
    "\n",
    "        #note: we don't store new_label, event_num in each iteration because they are the same in each iteration\n",
    "        #note: however, we store new_feature into all_matrix, because that does change per feature\n",
    "        all_matrix.append(new_feature)\n",
    "\n",
    "    #keep track of time taken for validation + evaluation\n",
    "    start = time.time()\n",
    "\n",
    "    clf = \"CNN\"\n",
    "    \n",
    "    #perform cross-validation and evaluation\n",
    "    all_result, each_result = cross_validation(all_matrix, new_label, event_num, seed, CV)\n",
    "\n",
    "    #save the overall and event-wise evaluation results to individual CSV files\n",
    "    save_result(featureName, 'all', clf, all_result)\n",
    "    save_result(featureName, 'each', clf, each_result)\n",
    "\n",
    "    #save the results in a variable as well (this part can be removeD)\n",
    "    result_all[clf] = all_result\n",
    "    result_eve[clf] = each_result\n",
    "\n",
    "    #total time taken for validation + evaluation\n",
    "    print(\"time used:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ac2a678-dca7-4950-924a-85c19e9ba3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smile\n",
      "target\n",
      "enzyme\n",
      "pathway\n",
      "Training for Fold 0\n",
      "Training for Feauture 0\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 437ms/step - accuracy: 0.3252 - loss: 2.3599 - val_accuracy: 0.6952 - val_loss: 1.0627\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 441ms/step - accuracy: 0.7293 - loss: 0.8908 - val_accuracy: 0.7786 - val_loss: 0.6891\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 444ms/step - accuracy: 0.8184 - loss: 0.5544 - val_accuracy: 0.8104 - val_loss: 0.5775\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 445ms/step - accuracy: 0.8622 - loss: 0.3971 - val_accuracy: 0.8332 - val_loss: 0.5229\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 443ms/step - accuracy: 0.8921 - loss: 0.2982 - val_accuracy: 0.8405 - val_loss: 0.5055\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9150 - loss: 0.2424 - val_accuracy: 0.8330 - val_loss: 0.5160\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.9338 - loss: 0.1892 - val_accuracy: 0.8389 - val_loss: 0.5451\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.9421 - loss: 0.1623 - val_accuracy: 0.8535 - val_loss: 0.5247\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.9529 - loss: 0.1327 - val_accuracy: 0.8523 - val_loss: 0.5710\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.9610 - loss: 0.1118 - val_accuracy: 0.8508 - val_loss: 0.6390\n",
      "model should be saved???\n",
      "<Functional name=functional_1, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step\n",
      "Training for Feauture 1\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 448ms/step - accuracy: 0.4259 - loss: 2.0813 - val_accuracy: 0.7181 - val_loss: 0.8985\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.7628 - loss: 0.7386 - val_accuracy: 0.7727 - val_loss: 0.6753\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 448ms/step - accuracy: 0.8236 - loss: 0.5041 - val_accuracy: 0.7962 - val_loss: 0.6052\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.8618 - loss: 0.3891 - val_accuracy: 0.7982 - val_loss: 0.6222\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.8828 - loss: 0.3230 - val_accuracy: 0.8073 - val_loss: 0.6004\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.8985 - loss: 0.2754 - val_accuracy: 0.8096 - val_loss: 0.6097\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.9112 - loss: 0.2462 - val_accuracy: 0.8140 - val_loss: 0.6077\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.9212 - loss: 0.2214 - val_accuracy: 0.8150 - val_loss: 0.6257\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.9293 - loss: 0.1997 - val_accuracy: 0.8142 - val_loss: 0.6335\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 445ms/step - accuracy: 0.9325 - loss: 0.1844 - val_accuracy: 0.8128 - val_loss: 0.6339\n",
      "model should be saved???\n",
      "<Functional name=functional_3, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step\n",
      "Training for Feauture 2\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 449ms/step - accuracy: 0.4006 - loss: 2.2093 - val_accuracy: 0.5975 - val_loss: 1.3585\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 459ms/step - accuracy: 0.6076 - loss: 1.2577 - val_accuracy: 0.6266 - val_loss: 1.1598\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.6548 - loss: 1.0368 - val_accuracy: 0.6515 - val_loss: 1.0653\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.6892 - loss: 0.9112 - val_accuracy: 0.6519 - val_loss: 1.0484\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.7038 - loss: 0.8399 - val_accuracy: 0.6533 - val_loss: 1.0507\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.7179 - loss: 0.7977 - val_accuracy: 0.6602 - val_loss: 1.0211\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.7361 - loss: 0.7424 - val_accuracy: 0.6531 - val_loss: 1.0715\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.7362 - loss: 0.7218 - val_accuracy: 0.6650 - val_loss: 1.0192\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 449ms/step - accuracy: 0.7503 - loss: 0.6925 - val_accuracy: 0.6575 - val_loss: 1.0277\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.7568 - loss: 0.6673 - val_accuracy: 0.6543 - val_loss: 1.0291\n",
      "model should be saved???\n",
      "<Functional name=functional_5, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step\n",
      "Training for Feauture 3\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 451ms/step - accuracy: 0.4335 - loss: 2.0701 - val_accuracy: 0.7145 - val_loss: 0.9058\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 453ms/step - accuracy: 0.7567 - loss: 0.7450 - val_accuracy: 0.7755 - val_loss: 0.6827\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 458ms/step - accuracy: 0.8193 - loss: 0.5139 - val_accuracy: 0.7902 - val_loss: 0.6276\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.8586 - loss: 0.4002 - val_accuracy: 0.7980 - val_loss: 0.6082\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.8765 - loss: 0.3362 - val_accuracy: 0.7941 - val_loss: 0.6295\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.8919 - loss: 0.2921 - val_accuracy: 0.8029 - val_loss: 0.6517\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8992 - loss: 0.2658 - val_accuracy: 0.7998 - val_loss: 0.6263\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 449ms/step - accuracy: 0.9118 - loss: 0.2399 - val_accuracy: 0.7954 - val_loss: 0.6827\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 447ms/step - accuracy: 0.9215 - loss: 0.2128 - val_accuracy: 0.8002 - val_loss: 0.6269\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9223 - loss: 0.2078 - val_accuracy: 0.8065 - val_loss: 0.6218\n",
      "model should be saved???\n",
      "<Functional name=functional_7, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Fold 1\n",
      "Training for Feauture 0\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 451ms/step - accuracy: 0.3311 - loss: 2.3349 - val_accuracy: 0.6905 - val_loss: 1.0378\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.7358 - loss: 0.8470 - val_accuracy: 0.7717 - val_loss: 0.7137\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8257 - loss: 0.5282 - val_accuracy: 0.7945 - val_loss: 0.6325\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.8695 - loss: 0.3807 - val_accuracy: 0.8313 - val_loss: 0.5440\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.8982 - loss: 0.2899 - val_accuracy: 0.8370 - val_loss: 0.5471\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9251 - loss: 0.2187 - val_accuracy: 0.8438 - val_loss: 0.5257\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.9374 - loss: 0.1847 - val_accuracy: 0.8478 - val_loss: 0.5503\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.9488 - loss: 0.1435 - val_accuracy: 0.8423 - val_loss: 0.5263\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.9587 - loss: 0.1202 - val_accuracy: 0.8529 - val_loss: 0.6163\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9631 - loss: 0.1110 - val_accuracy: 0.8446 - val_loss: 0.6671\n",
      "model should be saved???\n",
      "<Functional name=functional_9, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step\n",
      "Training for Feauture 1\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 450ms/step - accuracy: 0.4373 - loss: 2.0625 - val_accuracy: 0.7070 - val_loss: 0.9248\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.7611 - loss: 0.7255 - val_accuracy: 0.7700 - val_loss: 0.7011\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.8329 - loss: 0.4875 - val_accuracy: 0.7938 - val_loss: 0.6026\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.8626 - loss: 0.3862 - val_accuracy: 0.8059 - val_loss: 0.5757\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.8884 - loss: 0.3138 - val_accuracy: 0.8012 - val_loss: 0.5870\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 459ms/step - accuracy: 0.8982 - loss: 0.2733 - val_accuracy: 0.8053 - val_loss: 0.5809\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 449ms/step - accuracy: 0.9151 - loss: 0.2336 - val_accuracy: 0.8099 - val_loss: 0.6185\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9230 - loss: 0.2114 - val_accuracy: 0.8124 - val_loss: 0.5974\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.9274 - loss: 0.1982 - val_accuracy: 0.8140 - val_loss: 0.6460\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.9320 - loss: 0.1801 - val_accuracy: 0.8083 - val_loss: 0.6445\n",
      "model should be saved???\n",
      "<Functional name=functional_11, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step\n",
      "Training for Feauture 2\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 454ms/step - accuracy: 0.3751 - loss: 2.2853 - val_accuracy: 0.5792 - val_loss: 1.4366\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.6123 - loss: 1.2622 - val_accuracy: 0.6279 - val_loss: 1.2024\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.6564 - loss: 1.0389 - val_accuracy: 0.6400 - val_loss: 1.0986\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.6814 - loss: 0.9281 - val_accuracy: 0.6542 - val_loss: 1.0661\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.7058 - loss: 0.8401 - val_accuracy: 0.6478 - val_loss: 1.0551\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.7200 - loss: 0.7903 - val_accuracy: 0.6440 - val_loss: 1.0632\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.7326 - loss: 0.7515 - val_accuracy: 0.6572 - val_loss: 1.0325\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 448ms/step - accuracy: 0.7360 - loss: 0.7327 - val_accuracy: 0.6537 - val_loss: 1.0250\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.7484 - loss: 0.6941 - val_accuracy: 0.6530 - val_loss: 1.0346\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.7532 - loss: 0.6793 - val_accuracy: 0.6497 - val_loss: 1.0736\n",
      "model should be saved???\n",
      "<Functional name=functional_13, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 3\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 463ms/step - accuracy: 0.4232 - loss: 2.1136 - val_accuracy: 0.7022 - val_loss: 0.9424\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 470ms/step - accuracy: 0.7447 - loss: 0.7717 - val_accuracy: 0.7671 - val_loss: 0.7137\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 456ms/step - accuracy: 0.8246 - loss: 0.5077 - val_accuracy: 0.7835 - val_loss: 0.6251\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8549 - loss: 0.3988 - val_accuracy: 0.7935 - val_loss: 0.6024\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.8791 - loss: 0.3337 - val_accuracy: 0.7934 - val_loss: 0.6155\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.8980 - loss: 0.2860 - val_accuracy: 0.7996 - val_loss: 0.6103\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.9033 - loss: 0.2604 - val_accuracy: 0.7976 - val_loss: 0.6435\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 457ms/step - accuracy: 0.9144 - loss: 0.2367 - val_accuracy: 0.8079 - val_loss: 0.6370\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9198 - loss: 0.2190 - val_accuracy: 0.8037 - val_loss: 0.6303\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9236 - loss: 0.2034 - val_accuracy: 0.7989 - val_loss: 0.6218\n",
      "model should be saved???\n",
      "<Functional name=functional_15, built=True>\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step\n",
      "Training for Fold 2\n",
      "Training for Feauture 0\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 453ms/step - accuracy: 0.3406 - loss: 2.3369 - val_accuracy: 0.6803 - val_loss: 1.0495\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.7331 - loss: 0.8715 - val_accuracy: 0.7803 - val_loss: 0.6990\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.8212 - loss: 0.5320 - val_accuracy: 0.8165 - val_loss: 0.5851\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.8706 - loss: 0.3789 - val_accuracy: 0.8290 - val_loss: 0.5394\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.8981 - loss: 0.2982 - val_accuracy: 0.8324 - val_loss: 0.5560\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.9165 - loss: 0.2399 - val_accuracy: 0.8396 - val_loss: 0.5738\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9322 - loss: 0.1941 - val_accuracy: 0.8404 - val_loss: 0.5580\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.9435 - loss: 0.1624 - val_accuracy: 0.8375 - val_loss: 0.6169\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 449ms/step - accuracy: 0.9556 - loss: 0.1288 - val_accuracy: 0.8483 - val_loss: 0.5842\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.9636 - loss: 0.1120 - val_accuracy: 0.8458 - val_loss: 0.6588\n",
      "model should be saved???\n",
      "<Functional name=functional_17, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 1\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 453ms/step - accuracy: 0.4332 - loss: 2.0448 - val_accuracy: 0.7212 - val_loss: 0.8859\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.7606 - loss: 0.7308 - val_accuracy: 0.7720 - val_loss: 0.6917\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.8322 - loss: 0.4916 - val_accuracy: 0.7871 - val_loss: 0.6498\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.8647 - loss: 0.3817 - val_accuracy: 0.8027 - val_loss: 0.5988\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.8889 - loss: 0.3088 - val_accuracy: 0.8053 - val_loss: 0.6421\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.9053 - loss: 0.2588 - val_accuracy: 0.8082 - val_loss: 0.6197\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9141 - loss: 0.2318 - val_accuracy: 0.8037 - val_loss: 0.6299\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 464ms/step - accuracy: 0.9265 - loss: 0.2042 - val_accuracy: 0.8094 - val_loss: 0.6541\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.9287 - loss: 0.1936 - val_accuracy: 0.8082 - val_loss: 0.6908\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 456ms/step - accuracy: 0.9360 - loss: 0.1773 - val_accuracy: 0.8063 - val_loss: 0.6575\n",
      "model should be saved???\n",
      "<Functional name=functional_19, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 2\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 457ms/step - accuracy: 0.3685 - loss: 2.2804 - val_accuracy: 0.5746 - val_loss: 1.4324\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.6027 - loss: 1.2897 - val_accuracy: 0.6335 - val_loss: 1.1471\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.6501 - loss: 1.0437 - val_accuracy: 0.6516 - val_loss: 1.0704\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 457ms/step - accuracy: 0.6851 - loss: 0.9328 - val_accuracy: 0.6524 - val_loss: 1.0350\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.6992 - loss: 0.8588 - val_accuracy: 0.6712 - val_loss: 1.0056\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 457ms/step - accuracy: 0.7132 - loss: 0.8049 - val_accuracy: 0.6704 - val_loss: 1.0315\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 456ms/step - accuracy: 0.7276 - loss: 0.7683 - val_accuracy: 0.6658 - val_loss: 1.0491\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.7404 - loss: 0.7331 - val_accuracy: 0.6670 - val_loss: 1.0487\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.7428 - loss: 0.7060 - val_accuracy: 0.6666 - val_loss: 1.0512\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 456ms/step - accuracy: 0.7517 - loss: 0.6749 - val_accuracy: 0.6668 - val_loss: 1.0422\n",
      "model should be saved???\n",
      "<Functional name=functional_21, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 3\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 464ms/step - accuracy: 0.4565 - loss: 1.9966 - val_accuracy: 0.7174 - val_loss: 0.8929\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 473ms/step - accuracy: 0.7578 - loss: 0.7410 - val_accuracy: 0.7733 - val_loss: 0.6905\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 466ms/step - accuracy: 0.8198 - loss: 0.5149 - val_accuracy: 0.7929 - val_loss: 0.6202\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 463ms/step - accuracy: 0.8553 - loss: 0.4118 - val_accuracy: 0.7929 - val_loss: 0.6208\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.8769 - loss: 0.3405 - val_accuracy: 0.8015 - val_loss: 0.6376\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8880 - loss: 0.3014 - val_accuracy: 0.7981 - val_loss: 0.6412\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.9025 - loss: 0.2633 - val_accuracy: 0.7994 - val_loss: 0.6148\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 453ms/step - accuracy: 0.9149 - loss: 0.2355 - val_accuracy: 0.7969 - val_loss: 0.6382\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 462ms/step - accuracy: 0.9149 - loss: 0.2257 - val_accuracy: 0.7995 - val_loss: 0.6763\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9225 - loss: 0.2047 - val_accuracy: 0.8037 - val_loss: 0.6741\n",
      "model should be saved???\n",
      "<Functional name=functional_23, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Fold 3\n",
      "Training for Feauture 0\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 454ms/step - accuracy: 0.3427 - loss: 2.2955 - val_accuracy: 0.6897 - val_loss: 1.0446\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 457ms/step - accuracy: 0.7383 - loss: 0.8552 - val_accuracy: 0.7769 - val_loss: 0.7011\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 457ms/step - accuracy: 0.8242 - loss: 0.5281 - val_accuracy: 0.8079 - val_loss: 0.6034\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 462ms/step - accuracy: 0.8716 - loss: 0.3837 - val_accuracy: 0.8180 - val_loss: 0.5722\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8988 - loss: 0.2979 - val_accuracy: 0.8311 - val_loss: 0.5587\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 458ms/step - accuracy: 0.9175 - loss: 0.2313 - val_accuracy: 0.8362 - val_loss: 0.5668\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 465ms/step - accuracy: 0.9282 - loss: 0.1939 - val_accuracy: 0.8392 - val_loss: 0.5720\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 469ms/step - accuracy: 0.9445 - loss: 0.1566 - val_accuracy: 0.8486 - val_loss: 0.5790\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 458ms/step - accuracy: 0.9532 - loss: 0.1353 - val_accuracy: 0.8446 - val_loss: 0.6164\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.9608 - loss: 0.1142 - val_accuracy: 0.8407 - val_loss: 0.6583\n",
      "model should be saved???\n",
      "<Functional name=functional_25, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 1\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 455ms/step - accuracy: 0.4578 - loss: 1.9697 - val_accuracy: 0.7379 - val_loss: 0.8504\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 461ms/step - accuracy: 0.7740 - loss: 0.6910 - val_accuracy: 0.7720 - val_loss: 0.6804\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8353 - loss: 0.4651 - val_accuracy: 0.8008 - val_loss: 0.6069\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 460ms/step - accuracy: 0.8667 - loss: 0.3738 - val_accuracy: 0.8006 - val_loss: 0.5956\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.8869 - loss: 0.3097 - val_accuracy: 0.8032 - val_loss: 0.6244\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.9028 - loss: 0.2681 - val_accuracy: 0.8092 - val_loss: 0.5787\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 453ms/step - accuracy: 0.9152 - loss: 0.2319 - val_accuracy: 0.8156 - val_loss: 0.5841\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.9253 - loss: 0.2077 - val_accuracy: 0.8138 - val_loss: 0.6517\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.9314 - loss: 0.1890 - val_accuracy: 0.8119 - val_loss: 0.6183\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.9392 - loss: 0.1693 - val_accuracy: 0.8160 - val_loss: 0.6057\n",
      "model should be saved???\n",
      "<Functional name=functional_27, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 2\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 455ms/step - accuracy: 0.3681 - loss: 2.2601 - val_accuracy: 0.5672 - val_loss: 1.4632\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.6034 - loss: 1.2773 - val_accuracy: 0.6228 - val_loss: 1.1787\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 459ms/step - accuracy: 0.6608 - loss: 1.0272 - val_accuracy: 0.6407 - val_loss: 1.1014\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 456ms/step - accuracy: 0.6830 - loss: 0.9210 - val_accuracy: 0.6483 - val_loss: 1.0571\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.7035 - loss: 0.8426 - val_accuracy: 0.6456 - val_loss: 1.0600\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.7184 - loss: 0.7959 - val_accuracy: 0.6476 - val_loss: 1.0551\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 462ms/step - accuracy: 0.7283 - loss: 0.7595 - val_accuracy: 0.6558 - val_loss: 1.0626\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 461ms/step - accuracy: 0.7378 - loss: 0.7289 - val_accuracy: 0.6535 - val_loss: 1.0784\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 464ms/step - accuracy: 0.7502 - loss: 0.6881 - val_accuracy: 0.6556 - val_loss: 1.0387\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 457ms/step - accuracy: 0.7553 - loss: 0.6663 - val_accuracy: 0.6549 - val_loss: 1.0819\n",
      "model should be saved???\n",
      "<Functional name=functional_29, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 3\n",
      "Epoch 1/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 458ms/step - accuracy: 0.4456 - loss: 2.0320 - val_accuracy: 0.7210 - val_loss: 0.9053\n",
      "Epoch 2/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.7555 - loss: 0.7459 - val_accuracy: 0.7679 - val_loss: 0.7218\n",
      "Epoch 3/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.8220 - loss: 0.5025 - val_accuracy: 0.7863 - val_loss: 0.6404\n",
      "Epoch 4/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.8562 - loss: 0.4019 - val_accuracy: 0.7929 - val_loss: 0.6363\n",
      "Epoch 5/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 452ms/step - accuracy: 0.8801 - loss: 0.3325 - val_accuracy: 0.7994 - val_loss: 0.6142\n",
      "Epoch 6/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 460ms/step - accuracy: 0.8923 - loss: 0.2906 - val_accuracy: 0.8066 - val_loss: 0.6173\n",
      "Epoch 7/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 463ms/step - accuracy: 0.9042 - loss: 0.2615 - val_accuracy: 0.8060 - val_loss: 0.6334\n",
      "Epoch 8/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 458ms/step - accuracy: 0.9114 - loss: 0.2348 - val_accuracy: 0.7984 - val_loss: 0.6493\n",
      "Epoch 9/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 465ms/step - accuracy: 0.9193 - loss: 0.2197 - val_accuracy: 0.8102 - val_loss: 0.6419\n",
      "Epoch 10/10\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.9238 - loss: 0.2040 - val_accuracy: 0.8092 - val_loss: 0.6511\n",
      "model should be saved???\n",
      "<Functional name=functional_31, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step\n",
      "Training for Fold 4\n",
      "Training for Feauture 0\n",
      "Epoch 1/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 467ms/step - accuracy: 0.3225 - loss: 2.3760 - val_accuracy: 0.6875 - val_loss: 1.0258\n",
      "Epoch 2/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 466ms/step - accuracy: 0.7121 - loss: 0.9240 - val_accuracy: 0.7796 - val_loss: 0.7036\n",
      "Epoch 3/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.8173 - loss: 0.5514 - val_accuracy: 0.8166 - val_loss: 0.5567\n",
      "Epoch 4/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 455ms/step - accuracy: 0.8637 - loss: 0.3939 - val_accuracy: 0.8233 - val_loss: 0.5218\n",
      "Epoch 5/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 456ms/step - accuracy: 0.8866 - loss: 0.3244 - val_accuracy: 0.8473 - val_loss: 0.4742\n",
      "Epoch 6/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 455ms/step - accuracy: 0.9166 - loss: 0.2316 - val_accuracy: 0.8459 - val_loss: 0.4894\n",
      "Epoch 7/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.9320 - loss: 0.1945 - val_accuracy: 0.8561 - val_loss: 0.4946\n",
      "Epoch 8/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9464 - loss: 0.1537 - val_accuracy: 0.8489 - val_loss: 0.5346\n",
      "Epoch 9/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9535 - loss: 0.1431 - val_accuracy: 0.8444 - val_loss: 0.5887\n",
      "Epoch 10/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.9590 - loss: 0.1239 - val_accuracy: 0.8509 - val_loss: 0.5997\n",
      "model should be saved???\n",
      "<Functional name=functional_33, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 1\n",
      "Epoch 1/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 451ms/step - accuracy: 0.4533 - loss: 1.9726 - val_accuracy: 0.7109 - val_loss: 0.8839\n",
      "Epoch 2/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 448ms/step - accuracy: 0.7604 - loss: 0.7289 - val_accuracy: 0.7866 - val_loss: 0.6274\n",
      "Epoch 3/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.8245 - loss: 0.4930 - val_accuracy: 0.7875 - val_loss: 0.6100\n",
      "Epoch 4/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 453ms/step - accuracy: 0.8586 - loss: 0.3996 - val_accuracy: 0.8195 - val_loss: 0.5569\n",
      "Epoch 5/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 452ms/step - accuracy: 0.8841 - loss: 0.3178 - val_accuracy: 0.8092 - val_loss: 0.5597\n",
      "Epoch 6/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 451ms/step - accuracy: 0.9002 - loss: 0.2760 - val_accuracy: 0.8173 - val_loss: 0.5718\n",
      "Epoch 7/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9166 - loss: 0.2356 - val_accuracy: 0.8129 - val_loss: 0.5902\n",
      "Epoch 8/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9230 - loss: 0.2109 - val_accuracy: 0.8208 - val_loss: 0.5605\n",
      "Epoch 9/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 451ms/step - accuracy: 0.9282 - loss: 0.1973 - val_accuracy: 0.8226 - val_loss: 0.6159\n",
      "Epoch 10/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 448ms/step - accuracy: 0.9317 - loss: 0.1775 - val_accuracy: 0.8253 - val_loss: 0.5932\n",
      "model should be saved???\n",
      "<Functional name=functional_35, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step\n",
      "Training for Feauture 2\n",
      "Epoch 1/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 452ms/step - accuracy: 0.3798 - loss: 2.2590 - val_accuracy: 0.5538 - val_loss: 1.4490\n",
      "Epoch 2/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1855s\u001b[0m 8s/step - accuracy: 0.5920 - loss: 1.3120 - val_accuracy: 0.6330 - val_loss: 1.1602\n",
      "Epoch 3/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 440ms/step - accuracy: 0.6467 - loss: 1.0679 - val_accuracy: 0.6626 - val_loss: 1.0344\n",
      "Epoch 4/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 444ms/step - accuracy: 0.6812 - loss: 0.9320 - val_accuracy: 0.6645 - val_loss: 0.9986\n",
      "Epoch 5/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 452ms/step - accuracy: 0.6930 - loss: 0.8645 - val_accuracy: 0.6737 - val_loss: 0.9892\n",
      "Epoch 6/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 454ms/step - accuracy: 0.7117 - loss: 0.8221 - val_accuracy: 0.6750 - val_loss: 0.9876\n",
      "Epoch 7/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 461ms/step - accuracy: 0.7224 - loss: 0.7830 - val_accuracy: 0.6686 - val_loss: 0.9790\n",
      "Epoch 8/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 460ms/step - accuracy: 0.7327 - loss: 0.7483 - val_accuracy: 0.6684 - val_loss: 0.9943\n",
      "Epoch 9/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 459ms/step - accuracy: 0.7414 - loss: 0.7190 - val_accuracy: 0.6681 - val_loss: 1.0120\n",
      "Epoch 10/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.7430 - loss: 0.7065 - val_accuracy: 0.6742 - val_loss: 0.9816\n",
      "model should be saved???\n",
      "<Functional name=functional_37, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step\n",
      "Training for Feauture 3\n",
      "Epoch 1/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 465ms/step - accuracy: 0.4513 - loss: 2.0019 - val_accuracy: 0.7200 - val_loss: 0.8724\n",
      "Epoch 2/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 458ms/step - accuracy: 0.7560 - loss: 0.7373 - val_accuracy: 0.7798 - val_loss: 0.6584\n",
      "Epoch 3/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 457ms/step - accuracy: 0.8191 - loss: 0.5118 - val_accuracy: 0.7914 - val_loss: 0.6036\n",
      "Epoch 4/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 459ms/step - accuracy: 0.8517 - loss: 0.4121 - val_accuracy: 0.8034 - val_loss: 0.5676\n",
      "Epoch 5/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 459ms/step - accuracy: 0.8712 - loss: 0.3426 - val_accuracy: 0.8003 - val_loss: 0.6055\n",
      "Epoch 6/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 462ms/step - accuracy: 0.8892 - loss: 0.2976 - val_accuracy: 0.8030 - val_loss: 0.6017\n",
      "Epoch 7/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 452ms/step - accuracy: 0.9009 - loss: 0.2660 - val_accuracy: 0.8123 - val_loss: 0.6102\n",
      "Epoch 8/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 448ms/step - accuracy: 0.9092 - loss: 0.2443 - val_accuracy: 0.8101 - val_loss: 0.6088\n",
      "Epoch 9/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 450ms/step - accuracy: 0.9172 - loss: 0.2234 - val_accuracy: 0.8108 - val_loss: 0.6153\n",
      "Epoch 10/10\n",
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 466ms/step - accuracy: 0.9188 - loss: 0.2112 - val_accuracy: 0.8185 - val_loss: 0.5872\n",
      "model should be saved???\n",
      "<Functional name=functional_39, built=True>\n",
      "\u001b[1m233/233\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time used: 23083.72913312912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\milan\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
